{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词并去除停用词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import jieba\n",
    "\n",
    "stopwords = set()\n",
    "with open('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        stopwords.add(line.strip())\n",
    "text = \"这是一段需要进行分词的文本\"\n",
    "seg_list = jieba.cut(text, cut_all=False)\n",
    "seg_list = list(seg_list)\n",
    "filtered_words = []\n",
    "\n",
    "for word in seg_list:\n",
    "    if word not in stopwords:\n",
    "        filtered_words.append(word)\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "# 读取停用词表\n",
    "stop_words = set()\n",
    "with open('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        stop_words.add(line.strip())\n",
    "def preprocess(text):\n",
    "    # 使用jieba对文本进行分词\n",
    "    seg_list = jieba.cut(text, cut_all=False)\n",
    "\n",
    "    # 去除停用词\n",
    "    filtered_words = []\n",
    "    for word in seg_list:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    if filtered_words == []:\n",
    "        filtered_words.append('无')\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_requirements_df = pd.read_csv('./data/result1-1.csv')\n",
    "job_seekers_df = pd.read_csv('./data/result1-2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def academic_process(academic):\n",
    "    if academic == '大专 ':\n",
    "        return 2\n",
    "    elif academic == '本科 ':\n",
    "        return 3\n",
    "    elif academic == '本科 硕士 ':\n",
    "        return 4\n",
    "    elif academic == '博士 ':\n",
    "        return 5\n",
    "    elif academic == '技工 ':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def has_number(s):\n",
    "    \"\"\"判断字符串 s 中是否含有数字\"\"\"\n",
    "    pattern = r'\\d+'  # 定义匹配数字的正则表达式\n",
    "    match = re.search(pattern, s)  # 在字符串中搜索匹配项\n",
    "    return bool(match)  # 如果找到匹配项，返回 True，否则返回 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_process(experience):\n",
    "    if(type(experience) == float):\n",
    "        experience = str(experience)\n",
    "    if experience == '无经验' :\n",
    "        return 0\n",
    "    elif has_number(experience):\n",
    "        pattern = r\"\\d+\"\n",
    "        numbers = re.findall(pattern, experience)\n",
    "        return int(numbers[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\YHWK5\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.361 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "job_seekers_academic_df = pd.DataFrame(columns=['求职者id', '学历'])\n",
    "job_seekers_experience_df = pd.DataFrame(columns=['求职者id', '工作经验'])\n",
    "job_seekers_academic_df['求职者id'] = job_seekers_df['求职者id']\n",
    "job_seekers_experience_df['求职者id'] = job_seekers_df['求职者id']\n",
    "job_seekers_academic_df['学历'] = job_seekers_df['学历'].apply(academic_process)\n",
    "job_seekers_experience_df['工作经验'] = job_seekers_df['工作经验'].apply(experience_process)\n",
    "# 将job_seekers_academic_df['学历']转换为int类型，并保存到job_seekers_df['学历数值']\n",
    "job_seekers_df['学历数值'] = job_seekers_academic_df['学历'].astype(int)\n",
    "job_seekers_df['工作经验数值'] = job_seekers_experience_df['工作经验'].astype(int)\n",
    "job_seekers_df.fillna('无', inplace=True)\n",
    "job_seekers_df['自我评价-分词'] = job_seekers_df['自我评价'].apply(preprocess)\n",
    "job_seekers_df['自我评价-分词'] = job_seekers_df['自我评价-分词'].apply(lambda x: [i.replace('\\n', '无') for i in x])\n",
    "job_seekers_df.to_csv('result1-2_num.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_experience_process(experience):\n",
    "    if(type(experience) == float):\n",
    "        experience = str(experience)\n",
    "    if experience == '经验不限' or experience == '不限':\n",
    "        return 0\n",
    "    elif experience.isdigit():\n",
    "        return int(experience)\n",
    "    elif has_number(experience):\n",
    "        pattern = r\"\\d+\"\n",
    "        numbers = re.findall(pattern, experience)\n",
    "        return int(numbers[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_requirements_experience_df = pd.DataFrame(columns=['招聘信息id', '工作经验要求'])\n",
    "job_requirements_experience_df['招聘信息id'] = job_requirements_df['招聘信息id']\n",
    "job_requirements_experience_df['工作经验要求'] = job_requirements_df['工作经验要求'].apply(re_experience_process)\n",
    "job_requirements_df['工作经验要求数值'] = job_requirements_experience_df['工作经验要求'].astype(int)\n",
    "job_requirements_df['职位描述-分词'] = job_requirements_df['职位描述'].apply(preprocess)\n",
    "job_requirements_df['职位描述-分词'] = job_requirements_df['职位描述-分词'].apply(lambda x: [i.replace('\\n', '') for i in x])\n",
    "job_requirements_df.to_csv('result1-1_num.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_requirements_split_df = pd.DataFrame(columns=['职位描述-分词'])\n",
    "job_seekers_split_df = pd.DataFrame(columns=['自我评价-分词'])\n",
    "# read job_requirements_df '职位描述' column and preprocess it\n",
    "# save the result to a new frame called '职位描述-分词'\n",
    "# use apply() to apply the preprocess function to each row\n",
    "job_requirements_split_df['职位描述-分词'] = job_requirements_df['职位描述'].apply(preprocess)\n",
    "# use replace() to remove '/n' in the result\n",
    "job_requirements_split_df['职位描述-分词'] = job_requirements_split_df['职位描述-分词'].apply(lambda x: [i.replace('\\n', '') for i in x])\n",
    "job_requirements_split_df.to_csv('职位描述-分词.csv', index=False)\n",
    "# read job_seekers_df '自我评价' column and preprocess it\n",
    "# save the result to a new frame called '自我评价-分词'\n",
    "# use apply() to apply the preprocess function to each row\n",
    "job_seekers_df.fillna('', inplace=True)\n",
    "job_seekers_split_df['自我评价-分词'] = job_seekers_df['自我评价'].apply(preprocess)\n",
    "# use replace() to remove '/n' in the result\n",
    "job_seekers_split_df['自我评价-分词'] = job_seekers_split_df['自我评价-分词'].apply(lambda x: [i.replace('\\n', '') for i in x])\n",
    "job_seekers_split_df.to_csv('自我评价-分词.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行Word2vec训练，获取词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# 读取csv文件\n",
    "job_requirement_train = pd.read_csv('职位描述-分词.csv', header=0, delimiter=\",\")\n",
    "\n",
    "# 选择特定的列，并将每行文本转化为列表\n",
    "job_requirement_sentences = job_requirement_train['职位描述-分词'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# 设置Word2Vec模型的参数\n",
    "vector_size = 100    # 设置词向量的维度\n",
    "window = 5    # 设置上下文窗口的大小\n",
    "min_count = 1 # 忽略出现次数低于此值的单词\n",
    "workers = 4   # 设置用于训练模型的线程数\n",
    "\n",
    "# 训练Word2Vec模型\n",
    "requirement_model = Word2Vec(sentences=job_requirement_sentences, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "\n",
    "# 获取单词的向量表示\n",
    "# 获取词汇表中所有单词的列表\n",
    "words = list(requirement_model.wv.index_to_key)\n",
    "\n",
    "# 打印词汇表中的所有单词\n",
    "for word in words:\n",
    "    print(word)\n",
    "\n",
    "# 保存训练好的模型\n",
    "requirement_model.save('job_requirement_word2vec_model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文件\n",
    "job_seeker_train = pd.read_csv('自我评价-分词.csv', header=0, delimiter=\",\")\n",
    "\n",
    "# 选择特定的列，并将每行文本转化为列表\n",
    "job_seeker_sentences = job_seeker_train['自我评价-分词'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# 设置Word2Vec模型的参数\n",
    "vector_size = 100    # 设置词向量的维度\n",
    "window = 5    # 设置上下文窗口的大小\n",
    "min_count = 1 # 忽略出现次数低于此值的单词\n",
    "workers = 4   # 设置用于训练模型的线程数\n",
    "\n",
    "# 训练Word2Vec模型\n",
    "seeker_model = Word2Vec(sentences=job_seeker_sentences, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "\n",
    "# 获取单词的向量表示\n",
    "# 获取词汇表中所有单词的列表\n",
    "words = list(seeker_model.wv.index_to_key)\n",
    "\n",
    "# 打印词汇表中的所有单词\n",
    "for word in words:\n",
    "    print(word)\n",
    "\n",
    "# 保存训练好的模型\n",
    "seeker_model.save('job_seeker_word2vec_model.bin')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算相似性并推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 将文本数据转化为TF-IDF特征向量\n",
    "vectorizer = TfidfVectorizer()\n",
    "job_desc_tfidf = vectorizer.fit_transform(job_requirements_split_df['职位描述-分词'])\n",
    "self_intro_tfidf = vectorizer.transform(job_seekers_split_df['自我评价-分词'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 计算自我评价和职位描述之间的相似度矩阵\n",
    "similarity_matrix = cosine_similarity(self_intro_tfidf, job_desc_tfidf)\n",
    "\n",
    "# 求出每个求职者和每个招聘公司之间的相似度得分，并将结果保存到DataFrame中\n",
    "recommendations_df = pd.DataFrame(similarity_matrix, index=job_seekers_df['id'], columns=job_requirements_df['id'])\n",
    "\n",
    "# 找到每个求职者对应的最相似的n个公司\n",
    "n_recommendations = 3\n",
    "top_n_companies = recommendations_df.apply(lambda row: row.nlargest(n_recommendations).index.tolist(), axis=1)\n",
    "\n",
    "# 将推荐结果保存到CSV文件中\n",
    "top_n_companies_df = pd.DataFrame({'id': job_seekers_df['id'], 'top_n_companies': top_n_companies})\n",
    "top_n_companies_df.to_csv('top_n_companies.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
